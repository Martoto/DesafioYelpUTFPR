{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lista 7 - Exercício de Mineração de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questão 1 \n",
    "\n",
    "Use o dataset \"tweets_trump.csv\", que contém todos os tweets do D. Trump e faça o que é pedido abaixo.\n",
    "\n",
    "a) Utilizando o texto dos tweets identifique 5 tópicos latentes com o LDA, com um preprocessamento básico -- remoção de urls, remoção de pontuação, stemming e conversão para minúsculo. \n",
    "\n",
    "b) Avalie os tópicos encontrados. Algum preprocessamento a mais poderia ser útil para a produção de um melhor resultado?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltkNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: click in c:\\users\\danie\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\danie\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\danie\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from nltk) (2024.4.16)\n",
      "Requirement already satisfied: tqdm in c:\\users\\danie\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\danie\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from click->nltk) (0.4.5)\n",
      "Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 1.5/1.5 MB 1.7 MB/s eta 0:00:00\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.8.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: C:\\Users\\danie\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.7.4-cp39-cp39-win_amd64.whl.metadata (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.10-cp39-cp39-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.8-cp39-cp39-win_amd64.whl.metadata (8.6 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.9-cp39-cp39-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.3.0,>=8.2.2 (from spacy)\n",
      "  Downloading thinc-8.2.3-cp39-cp39-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.2-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.4.8-cp39-cp39-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.4.0,>=0.1.0 (from spacy)\n",
      "  Downloading weasel-0.3.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting typer<0.10.0,>=0.3.0 (from spacy)\n",
      "  Downloading typer-0.9.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<7.0.0,>=5.2.1 (from spacy)\n",
      "  Downloading smart_open-6.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\danie\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from spacy) (4.64.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\danie\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\danie\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from spacy) (1.10.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\danie\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\danie\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from spacy) (64.0.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\danie\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from spacy) (21.3)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Downloading langcodes-3.4.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\danie\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from spacy) (1.23.4)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading language_data-1.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\danie\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from packaging>=20.0->spacy) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\danie\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.3.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\danie\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\danie\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\danie\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\danie\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.6.15)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy)\n",
      "  Downloading blis-0.7.11-cp39-cp39-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.2.2->spacy)\n",
      "  Downloading confection-0.1.4-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\danie\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\danie\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.3)\n",
      "Collecting colorama (from tqdm<5.0.0,>=4.38.0->spacy)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting cloudpathlib<0.17.0,>=0.7.0 (from weasel<0.4.0,>=0.1.0->spacy)\n",
      "  Downloading cloudpathlib-0.16.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\danie\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from jinja2->spacy) (2.1.2)\n",
      "Collecting marisa-trie>=0.7.7 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading marisa_trie-1.1.1-cp39-cp39-win_amd64.whl.metadata (8.9 kB)\n",
      "Downloading spacy-3.7.4-cp39-cp39-win_amd64.whl (12.2 MB)\n",
      "   ---------------------------------------- 12.2/12.2 MB 3.2 MB/s eta 0:00:00\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.8-cp39-cp39-win_amd64.whl (39 kB)\n",
      "Downloading langcodes-3.4.0-py3-none-any.whl (182 kB)\n",
      "   ---------------------------------------- 182.0/182.0 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading murmurhash-1.0.10-cp39-cp39-win_amd64.whl (25 kB)\n",
      "Downloading preshed-3.0.9-cp39-cp39-win_amd64.whl (122 kB)\n",
      "   ---------------------------------------- 122.7/122.7 kB 3.6 MB/s eta 0:00:00\n",
      "Downloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "   ---------------------------------------- 57.0/57.0 kB 1.5 MB/s eta 0:00:00\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.4.8-cp39-cp39-win_amd64.whl (483 kB)\n",
      "   ---------------------------------------- 483.8/483.8 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading thinc-8.2.3-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 1.5/1.5 MB 3.8 MB/s eta 0:00:00\n",
      "Downloading typer-0.9.4-py3-none-any.whl (45 kB)\n",
      "   ---------------------------------------- 46.0/46.0 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.3.4-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 50.1/50.1 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading blis-0.7.11-cp39-cp39-win_amd64.whl (6.6 MB)\n",
      "   ---------------------------------------- 6.6/6.6 MB 3.8 MB/s eta 0:00:00\n",
      "Downloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
      "   ---------------------------------------- 45.0/45.0 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading confection-0.1.4-py3-none-any.whl (35 kB)\n",
      "Downloading language_data-1.2.0-py3-none-any.whl (5.4 MB)\n",
      "   ---------------------------------------- 5.4/5.4 MB 4.1 MB/s eta 0:00:00\n",
      "Downloading marisa_trie-1.1.1-cp39-cp39-win_amd64.whl (152 kB)\n",
      "   ---------------------------------------- 152.8/152.8 kB 2.3 MB/s eta 0:00:00\n",
      "Installing collected packages: cymem, spacy-loggers, spacy-legacy, smart-open, murmurhash, marisa-trie, colorama, cloudpathlib, catalogue, blis, wasabi, srsly, preshed, language-data, typer, langcodes, confection, weasel, thinc, spacy\n",
      "  Attempting uninstall: colorama\n",
      "    Found existing installation: colorama 0.4.5\n",
      "    Uninstalling colorama-0.4.5:\n",
      "      Successfully uninstalled colorama-0.4.5\n",
      "Successfully installed blis-0.7.11 catalogue-2.0.10 cloudpathlib-0.16.0 colorama-0.4.6 confection-0.1.4 cymem-2.0.8 langcodes-3.4.0 language-data-1.2.0 marisa-trie-1.1.1 murmurhash-1.0.10 preshed-3.0.9 smart-open-6.4.0 spacy-3.7.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.3 typer-0.9.4 wasabi-1.1.2 weasel-0.3.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: C:\\Users\\danie\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyLDAvis\n",
      "  Downloading pyLDAvis-3.4.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting numpy>=1.24.2 (from pyLDAvis)\n",
      "  Downloading numpy-1.26.4-cp39-cp39-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 61.0/61.0 kB 1.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy in c:\\users\\danie\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pyLDAvis) (1.10.1)\n",
      "Requirement already satisfied: pandas>=2.0.0 in c:\\users\\danie\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pyLDAvis) (2.2.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\danie\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pyLDAvis) (1.2.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\danie\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pyLDAvis) (3.1.2)\n",
      "Requirement already satisfied: numexpr in c:\\users\\danie\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pyLDAvis) (2.8.4)\n",
      "Collecting funcy (from pyLDAvis)\n",
      "  Downloading funcy-2.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\danie\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pyLDAvis) (1.4.2)\n",
      "Collecting gensim (from pyLDAvis)\n",
      "  Downloading gensim-4.3.2-cp39-cp39-win_amd64.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\danie\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pyLDAvis) (64.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\danie\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\danie\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas>=2.0.0->pyLDAvis) (2022.7.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\danie\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas>=2.0.0->pyLDAvis) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\danie\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.1.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\danie\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from gensim->pyLDAvis) (6.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\danie\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from jinja2->pyLDAvis) (2.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\danie\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.16.0)\n",
      "Downloading pyLDAvis-3.4.1-py3-none-any.whl (2.6 MB)\n",
      "   ---------------------------------------- 2.6/2.6 MB 3.7 MB/s eta 0:00:00\n",
      "Downloading numpy-1.26.4-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 15.8/15.8 MB 3.8 MB/s eta 0:00:00\n",
      "Downloading funcy-2.0-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gensim-4.3.2-cp39-cp39-win_amd64.whl (24.0 MB)\n",
      "   ---------------------------------------- 24.0/24.0 MB 4.1 MB/s eta 0:00:00\n",
      "Installing collected packages: funcy, numpy, gensim, pyLDAvis\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.4\n",
      "    Uninstalling numpy-1.23.4:\n",
      "      Successfully uninstalled numpy-1.23.4\n",
      "Successfully installed funcy-2.0 gensim-4.3.2 numpy-1.26.4 pyLDAvis-3.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\danie\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: C:\\Users\\danie\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk\n",
    "%pip install spacy\n",
    "%pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re, nltk, spacy, gensim # Sklearn\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pprint import pprint# Plotting tools\n",
    "import pyLDAvis\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:9: DeprecationWarning: invalid escape sequence \\w\n",
      "<>:9: DeprecationWarning: invalid escape sequence \\w\n",
      "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_21464\\1419421169.py:9: DeprecationWarning: invalid escape sequence \\w\n",
      "  return re.sub('RT @\\w+: ', \"\", text)\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\danie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['republicans', 'democrats', 'created', 'economic', 'problems'], ['thrilled', 'back', 'great', 'city', 'charlotte', 'north', 'carolina', 'thousands', 'hardworking', 'american', 'patriots', 'love', 'country', 'cherish', 'values', 'respect', 'laws', 'always', 'put', 'america', 'first', 'thank', 'wonderful', 'evening', 'kag2020'], ['read', 'letter', 'surveillance', 'court', 'obtained', 'cbs', 'news', 'questions', 'disciplinary', 'action', 'cho…'], ['unsolicited', 'mail', 'ballot', 'scam', 'major', 'threat', 'democracy', 'amp', 'democrats', 'know', 'almost', 'recent', 'elections', 'using', 'system', 'even', 'though', 'much', 'smaller', 'amp', 'far', 'fewer', 'ballots', 'count', 'ended', 'disaster', 'large', 'numbers', 'missing', 'ballots', 'amp', 'fraud'], ['friendly', 'telling', 'events', 'comeys', 'apparent', 'leaking', 'compliant', 'media', 'read', 'articles', 'tho…']]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('kaggle/input/trump_tweets/tweets_trump.csv')\n",
    "df['text'].head()\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "\n",
    "def remove_rt(text):\n",
    "    return re.sub('RT @\\w+: ', \"\", text)\n",
    "\n",
    "# Function to remove URLs from text\n",
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "# Function to remove punctuation from text\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words = [w for w in text.split() if w not in stop_words]\n",
    "    return words\n",
    "\n",
    "\n",
    "# Apply the preprocessing functions to the 'text' column\n",
    "df['text'] = df['text'].apply(remove_rt)\n",
    "df['text'] = df['text'].apply(remove_urls)\n",
    "df['text'] = df['text'].apply(remove_punctuation)\n",
    "df['text'] = df['text'].str.lower()\n",
    "\n",
    "\n",
    "data = df.text.values.tolist()\n",
    "data = [remove_stopwords(text) for text in data]\n",
    "\n",
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['republicans', 'democrats', 'created', 'economic', 'problems'],\n",
      " ['thrilled',\n",
      "  'back',\n",
      "  'great',\n",
      "  'city',\n",
      "  'charlotte',\n",
      "  'north',\n",
      "  'carolina',\n",
      "  'thousands',\n",
      "  'hardworking',\n",
      "  'american',\n",
      "  'patriots',\n",
      "  'love',\n",
      "  'country',\n",
      "  'cherish',\n",
      "  'values',\n",
      "  'respect',\n",
      "  'laws',\n",
      "  'always',\n",
      "  'put',\n",
      "  'america',\n",
      "  'first',\n",
      "  'thank',\n",
      "  'wonderful',\n",
      "  'evening',\n",
      "  'kag'],\n",
      " ['read',\n",
      "  'letter',\n",
      "  'surveillance',\n",
      "  'court',\n",
      "  'obtained',\n",
      "  'cbs',\n",
      "  'news',\n",
      "  'questions',\n",
      "  'disciplinary',\n",
      "  'action',\n",
      "  'cho'],\n",
      " ['unsolicited',\n",
      "  'mail',\n",
      "  'ballot',\n",
      "  'scam',\n",
      "  'major',\n",
      "  'threat',\n",
      "  'democracy',\n",
      "  'amp',\n",
      "  'democrats',\n",
      "  'know',\n",
      "  'almost',\n",
      "  'recent',\n",
      "  'elections',\n",
      "  'using',\n",
      "  'system',\n",
      "  'even',\n",
      "  'though',\n",
      "  'much',\n",
      "  'smaller',\n",
      "  'amp',\n",
      "  'far',\n",
      "  'fewer',\n",
      "  'ballots',\n",
      "  'count',\n",
      "  'ended',\n",
      "  'disaster',\n",
      "  'large',\n",
      "  'numbers',\n",
      "  'missing',\n",
      "  'ballots',\n",
      "  'amp',\n",
      "  'fraud'],\n",
      " ['friendly',\n",
      "  'telling',\n",
      "  'events',\n",
      "  'comeys',\n",
      "  'apparent',\n",
      "  'leaking',\n",
      "  'compliant',\n",
      "  'media',\n",
      "  'read',\n",
      "  'articles',\n",
      "  'tho']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "        \n",
    "data_words = list(sent_to_words(data))\n",
    "pprint(data_words[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']): #'NOUN', 'ADJ', 'VERB', 'ADV'\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append(\" \".join([token.lemma_ if token.lemma_ not in ['-PRON-'] else '' for token in doc if token.pos_ in allowed_postags]))\n",
    "    return texts_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E941] Can't find model 'en'. It looks like you're trying to load a model from a shortcut, which is obsolete as of spaCy v3.0. To load the model, use its full name instead:\n\nnlp = spacy.load(\"en_core_web_sm\")\n\nFor more details on the available models, see the models directory: https://spacy.io/models and if you want to create a blank model, use spacy.blank: nlp = spacy.blank(\"en\")",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43men\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparser\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mner\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m data_lemmatized \u001b[38;5;241m=\u001b[39m lemmatization(data_words, allowed_postags\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNOUN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVERB\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\spacy\\__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[0;32m     28\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[0;32m     35\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[0;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\spacy\\util.py:471\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m load_model_from_path(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[1;32m--> 471\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE941\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname, full\u001b[38;5;241m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE050\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname))\n",
      "\u001b[1;31mOSError\u001b[0m: [E941] Can't find model 'en'. It looks like you're trying to load a model from a shortcut, which is obsolete as of spaCy v3.0. To load the model, use its full name instead:\n\nnlp = spacy.load(\"en_core_web_sm\")\n\nFor more details on the available models, see the models directory: https://spacy.io/models and if you want to create a blank model, use spacy.blank: nlp = spacy.blank(\"en\")"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "data_words = lemmatization(data_words, allowed_postags=['NOUN', 'VERB']) \n",
    "data_words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['create economic problem',\n",
       " 'thrill back great city thousand hardworke american patriot love country cherish value respect law always put first thank wonderful evening kag',\n",
       " 'read letter surveillance court obtain news question disciplinary action cho',\n",
       " 'unsolicite mail ballot scam major threat democracy know almost recent election use system even much small amp far few ballot count end disaster large number miss ballot amp fraud',\n",
       " 'friendly tell event comey apparent leak compliant medium article tho']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 748)\t1\n",
      "  (0, 1048)\t1\n",
      "  (0, 2554)\t1\n",
      "  (1, 3329)\t1\n",
      "  (1, 250)\t1\n",
      "  (1, 1469)\t1\n",
      "  (1, 547)\t1\n",
      "  (1, 3325)\t1\n",
      "  (1, 1515)\t1\n",
      "  (1, 124)\t1\n",
      "  (1, 2365)\t1\n",
      "  (1, 1962)\t1\n",
      "  (1, 727)\t1\n",
      "  (1, 528)\t1\n",
      "  (1, 3546)\t1\n",
      "  (1, 2777)\t1\n",
      "  (1, 1870)\t1\n",
      "  (1, 113)\t1\n",
      "  (1, 2616)\t1\n",
      "  (1, 1296)\t1\n",
      "  (1, 3299)\t1\n",
      "  (1, 3686)\t1\n",
      "  (1, 1157)\t1\n",
      "  (1, 1818)\t1\n",
      "  (2, 2664)\t1\n",
      "  :\t:\n",
      "  (56567, 931)\t1\n",
      "  (56568, 823)\t2\n",
      "  (56568, 3591)\t1\n",
      "  (56568, 2525)\t1\n",
      "  (56568, 1934)\t1\n",
      "  (56568, 3298)\t1\n",
      "  (56569, 124)\t3\n",
      "  (56569, 113)\t1\n",
      "  (56569, 2616)\t1\n",
      "  (56569, 1296)\t1\n",
      "  (56569, 2588)\t1\n",
      "  (56569, 1995)\t1\n",
      "  (56569, 3215)\t1\n",
      "  (56569, 3209)\t1\n",
      "  (56569, 3690)\t5\n",
      "  (56569, 2288)\t1\n",
      "  (56569, 3008)\t1\n",
      "  (56569, 1223)\t2\n",
      "  (56569, 713)\t1\n",
      "  (56570, 3606)\t1\n",
      "  (56570, 2869)\t1\n",
      "  (56570, 3683)\t1\n",
      "  (56570, 1434)\t1\n",
      "  (56570, 2929)\t1\n",
      "  (56570, 3186)\t1\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word',       \n",
    "                             min_df=10,\n",
    "                             lowercase=True,                   \n",
    "                             token_pattern='[a-zA-Z0-9]{3,}',  \n",
    "                              max_features=50000,             )\n",
    "data_vectorized = vectorizer.fit_transform(data_words)\n",
    "\n",
    "print(data_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
    " evaluate_every=-1, learning_decay=0.7,\n",
    " learning_method='online', learning_offset=10.0,\n",
    " max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
    " n_components=5, n_jobs=-1, perp_tol=0.1,\n",
    " random_state=100, topic_word_prior=None,\n",
    " total_samples=1000000.0, verbose=0)\n",
    "\n",
    "lda_output = lda_model.fit_transform(data_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Likelihood:  -2931093.843290576\n",
      "Perplexity:  1443.6077514931105\n",
      "{'batch_size': 128,\n",
      " 'doc_topic_prior': None,\n",
      " 'evaluate_every': -1,\n",
      " 'learning_decay': 0.7,\n",
      " 'learning_method': 'online',\n",
      " 'learning_offset': 10.0,\n",
      " 'max_doc_update_iter': 100,\n",
      " 'max_iter': 10,\n",
      " 'mean_change_tol': 0.001,\n",
      " 'n_components': 5,\n",
      " 'n_jobs': -1,\n",
      " 'perp_tol': 0.1,\n",
      " 'random_state': 100,\n",
      " 'topic_word_prior': None,\n",
      " 'total_samples': 1000000.0,\n",
      " 'verbose': 0}\n"
     ]
    }
   ],
   "source": [
    "# Log Likelyhood: Higher the better\n",
    "print(\"Log Likelihood: \", lda_model.score(data_vectorized))# Perplexity: Lower the better. Perplexity = exp(-1. * log-likelihood per word)\n",
    "print(\"Perplexity: \", lda_model.perplexity(data_vectorized))# See model parameters\n",
    "pprint(lda_model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_21464\\1269774312.py:14: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  df_document_topics = df_document_topic.head(15).style.applymap(color_green).applymap(make_bold)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_df342_row0_col0, #T_df342_row0_col1, #T_df342_row0_col2, #T_df342_row0_col3, #T_df342_row1_col1, #T_df342_row1_col2, #T_df342_row1_col4, #T_df342_row2_col2, #T_df342_row2_col4, #T_df342_row2_col5, #T_df342_row3_col0, #T_df342_row3_col1, #T_df342_row3_col4, #T_df342_row4_col0, #T_df342_row4_col1, #T_df342_row4_col2, #T_df342_row4_col4, #T_df342_row5_col2, #T_df342_row5_col3, #T_df342_row5_col4, #T_df342_row5_col5, #T_df342_row6_col0, #T_df342_row6_col1, #T_df342_row6_col4, #T_df342_row7_col5, #T_df342_row8_col5, #T_df342_row9_col5, #T_df342_row10_col5, #T_df342_row11_col5, #T_df342_row12_col1, #T_df342_row12_col2, #T_df342_row12_col3, #T_df342_row12_col5, #T_df342_row13_col1, #T_df342_row13_col2, #T_df342_row13_col3, #T_df342_row13_col4, #T_df342_row13_col5, #T_df342_row14_col0, #T_df342_row14_col1, #T_df342_row14_col2, #T_df342_row14_col4 {\n",
       "  color: black;\n",
       "  font-weight: 400;\n",
       "}\n",
       "#T_df342_row0_col4, #T_df342_row0_col5, #T_df342_row1_col0, #T_df342_row1_col3, #T_df342_row1_col5, #T_df342_row2_col0, #T_df342_row2_col1, #T_df342_row2_col3, #T_df342_row3_col2, #T_df342_row3_col3, #T_df342_row3_col5, #T_df342_row4_col3, #T_df342_row4_col5, #T_df342_row5_col0, #T_df342_row5_col1, #T_df342_row6_col2, #T_df342_row6_col3, #T_df342_row6_col5, #T_df342_row7_col0, #T_df342_row7_col1, #T_df342_row7_col2, #T_df342_row7_col3, #T_df342_row7_col4, #T_df342_row8_col0, #T_df342_row8_col1, #T_df342_row8_col2, #T_df342_row8_col3, #T_df342_row8_col4, #T_df342_row9_col0, #T_df342_row9_col1, #T_df342_row9_col2, #T_df342_row9_col3, #T_df342_row9_col4, #T_df342_row10_col0, #T_df342_row10_col1, #T_df342_row10_col2, #T_df342_row10_col3, #T_df342_row10_col4, #T_df342_row11_col0, #T_df342_row11_col1, #T_df342_row11_col2, #T_df342_row11_col3, #T_df342_row11_col4, #T_df342_row12_col0, #T_df342_row12_col4, #T_df342_row13_col0, #T_df342_row14_col3, #T_df342_row14_col5 {\n",
       "  color: green;\n",
       "  font-weight: 700;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_df342\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_df342_level0_col0\" class=\"col_heading level0 col0\" >Topic0</th>\n",
       "      <th id=\"T_df342_level0_col1\" class=\"col_heading level0 col1\" >Topic1</th>\n",
       "      <th id=\"T_df342_level0_col2\" class=\"col_heading level0 col2\" >Topic2</th>\n",
       "      <th id=\"T_df342_level0_col3\" class=\"col_heading level0 col3\" >Topic3</th>\n",
       "      <th id=\"T_df342_level0_col4\" class=\"col_heading level0 col4\" >Topic4</th>\n",
       "      <th id=\"T_df342_level0_col5\" class=\"col_heading level0 col5\" >dominant_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_df342_level0_row0\" class=\"row_heading level0 row0\" >Doc0</th>\n",
       "      <td id=\"T_df342_row0_col0\" class=\"data row0 col0\" >0.050000</td>\n",
       "      <td id=\"T_df342_row0_col1\" class=\"data row0 col1\" >0.050000</td>\n",
       "      <td id=\"T_df342_row0_col2\" class=\"data row0 col2\" >0.050000</td>\n",
       "      <td id=\"T_df342_row0_col3\" class=\"data row0 col3\" >0.050000</td>\n",
       "      <td id=\"T_df342_row0_col4\" class=\"data row0 col4\" >0.800000</td>\n",
       "      <td id=\"T_df342_row0_col5\" class=\"data row0 col5\" >4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df342_level0_row1\" class=\"row_heading level0 row1\" >Doc1</th>\n",
       "      <td id=\"T_df342_row1_col0\" class=\"data row1 col0\" >0.140000</td>\n",
       "      <td id=\"T_df342_row1_col1\" class=\"data row1 col1\" >0.010000</td>\n",
       "      <td id=\"T_df342_row1_col2\" class=\"data row1 col2\" >0.010000</td>\n",
       "      <td id=\"T_df342_row1_col3\" class=\"data row1 col3\" >0.790000</td>\n",
       "      <td id=\"T_df342_row1_col4\" class=\"data row1 col4\" >0.050000</td>\n",
       "      <td id=\"T_df342_row1_col5\" class=\"data row1 col5\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df342_level0_row2\" class=\"row_heading level0 row2\" >Doc2</th>\n",
       "      <td id=\"T_df342_row2_col0\" class=\"data row2 col0\" >0.690000</td>\n",
       "      <td id=\"T_df342_row2_col1\" class=\"data row2 col1\" >0.130000</td>\n",
       "      <td id=\"T_df342_row2_col2\" class=\"data row2 col2\" >0.020000</td>\n",
       "      <td id=\"T_df342_row2_col3\" class=\"data row2 col3\" >0.130000</td>\n",
       "      <td id=\"T_df342_row2_col4\" class=\"data row2 col4\" >0.020000</td>\n",
       "      <td id=\"T_df342_row2_col5\" class=\"data row2 col5\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df342_level0_row3\" class=\"row_heading level0 row3\" >Doc3</th>\n",
       "      <td id=\"T_df342_row3_col0\" class=\"data row3 col0\" >0.010000</td>\n",
       "      <td id=\"T_df342_row3_col1\" class=\"data row3 col1\" >0.010000</td>\n",
       "      <td id=\"T_df342_row3_col2\" class=\"data row3 col2\" >0.250000</td>\n",
       "      <td id=\"T_df342_row3_col3\" class=\"data row3 col3\" >0.730000</td>\n",
       "      <td id=\"T_df342_row3_col4\" class=\"data row3 col4\" >0.010000</td>\n",
       "      <td id=\"T_df342_row3_col5\" class=\"data row3 col5\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df342_level0_row4\" class=\"row_heading level0 row4\" >Doc4</th>\n",
       "      <td id=\"T_df342_row4_col0\" class=\"data row4 col0\" >0.030000</td>\n",
       "      <td id=\"T_df342_row4_col1\" class=\"data row4 col1\" >0.030000</td>\n",
       "      <td id=\"T_df342_row4_col2\" class=\"data row4 col2\" >0.030000</td>\n",
       "      <td id=\"T_df342_row4_col3\" class=\"data row4 col3\" >0.900000</td>\n",
       "      <td id=\"T_df342_row4_col4\" class=\"data row4 col4\" >0.030000</td>\n",
       "      <td id=\"T_df342_row4_col5\" class=\"data row4 col5\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df342_level0_row5\" class=\"row_heading level0 row5\" >Doc5</th>\n",
       "      <td id=\"T_df342_row5_col0\" class=\"data row5 col0\" >0.820000</td>\n",
       "      <td id=\"T_df342_row5_col1\" class=\"data row5 col1\" >0.120000</td>\n",
       "      <td id=\"T_df342_row5_col2\" class=\"data row5 col2\" >0.020000</td>\n",
       "      <td id=\"T_df342_row5_col3\" class=\"data row5 col3\" >0.020000</td>\n",
       "      <td id=\"T_df342_row5_col4\" class=\"data row5 col4\" >0.020000</td>\n",
       "      <td id=\"T_df342_row5_col5\" class=\"data row5 col5\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df342_level0_row6\" class=\"row_heading level0 row6\" >Doc6</th>\n",
       "      <td id=\"T_df342_row6_col0\" class=\"data row6 col0\" >0.040000</td>\n",
       "      <td id=\"T_df342_row6_col1\" class=\"data row6 col1\" >0.040000</td>\n",
       "      <td id=\"T_df342_row6_col2\" class=\"data row6 col2\" >0.160000</td>\n",
       "      <td id=\"T_df342_row6_col3\" class=\"data row6 col3\" >0.720000</td>\n",
       "      <td id=\"T_df342_row6_col4\" class=\"data row6 col4\" >0.040000</td>\n",
       "      <td id=\"T_df342_row6_col5\" class=\"data row6 col5\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df342_level0_row7\" class=\"row_heading level0 row7\" >Doc7</th>\n",
       "      <td id=\"T_df342_row7_col0\" class=\"data row7 col0\" >0.200000</td>\n",
       "      <td id=\"T_df342_row7_col1\" class=\"data row7 col1\" >0.200000</td>\n",
       "      <td id=\"T_df342_row7_col2\" class=\"data row7 col2\" >0.200000</td>\n",
       "      <td id=\"T_df342_row7_col3\" class=\"data row7 col3\" >0.200000</td>\n",
       "      <td id=\"T_df342_row7_col4\" class=\"data row7 col4\" >0.200000</td>\n",
       "      <td id=\"T_df342_row7_col5\" class=\"data row7 col5\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df342_level0_row8\" class=\"row_heading level0 row8\" >Doc8</th>\n",
       "      <td id=\"T_df342_row8_col0\" class=\"data row8 col0\" >0.200000</td>\n",
       "      <td id=\"T_df342_row8_col1\" class=\"data row8 col1\" >0.200000</td>\n",
       "      <td id=\"T_df342_row8_col2\" class=\"data row8 col2\" >0.200000</td>\n",
       "      <td id=\"T_df342_row8_col3\" class=\"data row8 col3\" >0.200000</td>\n",
       "      <td id=\"T_df342_row8_col4\" class=\"data row8 col4\" >0.200000</td>\n",
       "      <td id=\"T_df342_row8_col5\" class=\"data row8 col5\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df342_level0_row9\" class=\"row_heading level0 row9\" >Doc9</th>\n",
       "      <td id=\"T_df342_row9_col0\" class=\"data row9 col0\" >0.200000</td>\n",
       "      <td id=\"T_df342_row9_col1\" class=\"data row9 col1\" >0.200000</td>\n",
       "      <td id=\"T_df342_row9_col2\" class=\"data row9 col2\" >0.200000</td>\n",
       "      <td id=\"T_df342_row9_col3\" class=\"data row9 col3\" >0.200000</td>\n",
       "      <td id=\"T_df342_row9_col4\" class=\"data row9 col4\" >0.200000</td>\n",
       "      <td id=\"T_df342_row9_col5\" class=\"data row9 col5\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df342_level0_row10\" class=\"row_heading level0 row10\" >Doc10</th>\n",
       "      <td id=\"T_df342_row10_col0\" class=\"data row10 col0\" >0.200000</td>\n",
       "      <td id=\"T_df342_row10_col1\" class=\"data row10 col1\" >0.200000</td>\n",
       "      <td id=\"T_df342_row10_col2\" class=\"data row10 col2\" >0.200000</td>\n",
       "      <td id=\"T_df342_row10_col3\" class=\"data row10 col3\" >0.200000</td>\n",
       "      <td id=\"T_df342_row10_col4\" class=\"data row10 col4\" >0.200000</td>\n",
       "      <td id=\"T_df342_row10_col5\" class=\"data row10 col5\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df342_level0_row11\" class=\"row_heading level0 row11\" >Doc11</th>\n",
       "      <td id=\"T_df342_row11_col0\" class=\"data row11 col0\" >0.200000</td>\n",
       "      <td id=\"T_df342_row11_col1\" class=\"data row11 col1\" >0.200000</td>\n",
       "      <td id=\"T_df342_row11_col2\" class=\"data row11 col2\" >0.200000</td>\n",
       "      <td id=\"T_df342_row11_col3\" class=\"data row11 col3\" >0.200000</td>\n",
       "      <td id=\"T_df342_row11_col4\" class=\"data row11 col4\" >0.200000</td>\n",
       "      <td id=\"T_df342_row11_col5\" class=\"data row11 col5\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df342_level0_row12\" class=\"row_heading level0 row12\" >Doc12</th>\n",
       "      <td id=\"T_df342_row12_col0\" class=\"data row12 col0\" >0.820000</td>\n",
       "      <td id=\"T_df342_row12_col1\" class=\"data row12 col1\" >0.020000</td>\n",
       "      <td id=\"T_df342_row12_col2\" class=\"data row12 col2\" >0.020000</td>\n",
       "      <td id=\"T_df342_row12_col3\" class=\"data row12 col3\" >0.020000</td>\n",
       "      <td id=\"T_df342_row12_col4\" class=\"data row12 col4\" >0.120000</td>\n",
       "      <td id=\"T_df342_row12_col5\" class=\"data row12 col5\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df342_level0_row13\" class=\"row_heading level0 row13\" >Doc13</th>\n",
       "      <td id=\"T_df342_row13_col0\" class=\"data row13 col0\" >0.840000</td>\n",
       "      <td id=\"T_df342_row13_col1\" class=\"data row13 col1\" >0.040000</td>\n",
       "      <td id=\"T_df342_row13_col2\" class=\"data row13 col2\" >0.040000</td>\n",
       "      <td id=\"T_df342_row13_col3\" class=\"data row13 col3\" >0.040000</td>\n",
       "      <td id=\"T_df342_row13_col4\" class=\"data row13 col4\" >0.040000</td>\n",
       "      <td id=\"T_df342_row13_col5\" class=\"data row13 col5\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df342_level0_row14\" class=\"row_heading level0 row14\" >Doc14</th>\n",
       "      <td id=\"T_df342_row14_col0\" class=\"data row14 col0\" >0.100000</td>\n",
       "      <td id=\"T_df342_row14_col1\" class=\"data row14 col1\" >0.100000</td>\n",
       "      <td id=\"T_df342_row14_col2\" class=\"data row14 col2\" >0.100000</td>\n",
       "      <td id=\"T_df342_row14_col3\" class=\"data row14 col3\" >0.600000</td>\n",
       "      <td id=\"T_df342_row14_col4\" class=\"data row14 col4\" >0.100000</td>\n",
       "      <td id=\"T_df342_row14_col5\" class=\"data row14 col5\" >3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1a6395a8760>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Document — Topic Matrix\n",
    "lda_output = lda_model.transform(data_vectorized)# column names\n",
    "topicnames = ['Topic' + str(i) for i in range(lda_model.n_components)]# index names\n",
    "docnames = ['Doc' + str(i) for i in range(len(data))]# Make the pandas dataframe\n",
    "df_document_topic = pd.DataFrame(np.round(lda_output, 2), columns=topicnames, index=docnames)# Get dominant topic for each document\n",
    "dominant_topic = np.argmax(df_document_topic.values, axis=1)\n",
    "df_document_topic['dominant_topic'] = dominant_topic# Styling\n",
    "def color_green(val):\n",
    " color = 'green' if val > .1 else 'black'\n",
    " return 'color: {col}'.format(col=color)\n",
    "def make_bold(val):\n",
    " weight = 700 if val > .1 else 400\n",
    " return 'font-weight: {weight}'.format(weight=weight)# Apply Style\n",
    "df_document_topics = df_document_topic.head(15).style.applymap(color_green).applymap(make_bold)\n",
    "df_document_topics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandon</th>\n",
       "      <th>aberdeen</th>\n",
       "      <th>aberdeenshire</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abolish</th>\n",
       "      <th>abortion</th>\n",
       "      <th>absentee</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>yearly</th>\n",
       "      <th>yell</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yrs</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic0</th>\n",
       "      <td>0.205733</td>\n",
       "      <td>0.201779</td>\n",
       "      <td>0.202053</td>\n",
       "      <td>0.202419</td>\n",
       "      <td>61.396126</td>\n",
       "      <td>0.205467</td>\n",
       "      <td>13.950429</td>\n",
       "      <td>0.200494</td>\n",
       "      <td>0.204350</td>\n",
       "      <td>189.162315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206718</td>\n",
       "      <td>0.204780</td>\n",
       "      <td>0.200825</td>\n",
       "      <td>0.204247</td>\n",
       "      <td>3.288409</td>\n",
       "      <td>0.204266</td>\n",
       "      <td>0.218053</td>\n",
       "      <td>0.202620</td>\n",
       "      <td>0.204609</td>\n",
       "      <td>0.202741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic1</th>\n",
       "      <td>33.496948</td>\n",
       "      <td>0.204027</td>\n",
       "      <td>0.201768</td>\n",
       "      <td>0.206226</td>\n",
       "      <td>0.206138</td>\n",
       "      <td>31.000032</td>\n",
       "      <td>0.204815</td>\n",
       "      <td>0.200698</td>\n",
       "      <td>0.204487</td>\n",
       "      <td>0.205118</td>\n",
       "      <td>...</td>\n",
       "      <td>1002.288713</td>\n",
       "      <td>0.204749</td>\n",
       "      <td>8.360062</td>\n",
       "      <td>450.718910</td>\n",
       "      <td>7.669560</td>\n",
       "      <td>0.204423</td>\n",
       "      <td>0.204720</td>\n",
       "      <td>13.986065</td>\n",
       "      <td>0.203087</td>\n",
       "      <td>0.202043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic2</th>\n",
       "      <td>0.204126</td>\n",
       "      <td>0.203269</td>\n",
       "      <td>0.202943</td>\n",
       "      <td>0.203381</td>\n",
       "      <td>141.595638</td>\n",
       "      <td>0.202266</td>\n",
       "      <td>0.202414</td>\n",
       "      <td>26.917049</td>\n",
       "      <td>60.517739</td>\n",
       "      <td>0.205853</td>\n",
       "      <td>...</td>\n",
       "      <td>1256.111777</td>\n",
       "      <td>0.202394</td>\n",
       "      <td>0.201445</td>\n",
       "      <td>0.205282</td>\n",
       "      <td>0.205315</td>\n",
       "      <td>0.202101</td>\n",
       "      <td>20.095576</td>\n",
       "      <td>0.207948</td>\n",
       "      <td>0.203849</td>\n",
       "      <td>0.202028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic3</th>\n",
       "      <td>0.207199</td>\n",
       "      <td>0.202392</td>\n",
       "      <td>0.200523</td>\n",
       "      <td>0.204977</td>\n",
       "      <td>0.206519</td>\n",
       "      <td>0.201801</td>\n",
       "      <td>0.202276</td>\n",
       "      <td>0.200807</td>\n",
       "      <td>0.205753</td>\n",
       "      <td>0.206344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206351</td>\n",
       "      <td>0.203045</td>\n",
       "      <td>0.201754</td>\n",
       "      <td>0.206369</td>\n",
       "      <td>127.787660</td>\n",
       "      <td>0.203026</td>\n",
       "      <td>0.208391</td>\n",
       "      <td>0.202225</td>\n",
       "      <td>0.201677</td>\n",
       "      <td>0.201470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic4</th>\n",
       "      <td>0.206171</td>\n",
       "      <td>22.298175</td>\n",
       "      <td>8.806585</td>\n",
       "      <td>41.203826</td>\n",
       "      <td>0.208902</td>\n",
       "      <td>0.204321</td>\n",
       "      <td>0.202470</td>\n",
       "      <td>0.200302</td>\n",
       "      <td>0.203170</td>\n",
       "      <td>47.579606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209091</td>\n",
       "      <td>11.707221</td>\n",
       "      <td>0.202593</td>\n",
       "      <td>0.205504</td>\n",
       "      <td>154.308501</td>\n",
       "      <td>143.291485</td>\n",
       "      <td>0.207629</td>\n",
       "      <td>0.201928</td>\n",
       "      <td>15.891660</td>\n",
       "      <td>57.513947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3723 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          abandon   aberdeen  aberdeenshire    ability        able    abolish  \\\n",
       "Topic0   0.205733   0.201779       0.202053   0.202419   61.396126   0.205467   \n",
       "Topic1  33.496948   0.204027       0.201768   0.206226    0.206138  31.000032   \n",
       "Topic2   0.204126   0.203269       0.202943   0.203381  141.595638   0.202266   \n",
       "Topic3   0.207199   0.202392       0.200523   0.204977    0.206519   0.201801   \n",
       "Topic4   0.206171  22.298175       8.806585  41.203826    0.208902   0.204321   \n",
       "\n",
       "         abortion   absentee   absolute  absolutely  ...         year  \\\n",
       "Topic0  13.950429   0.200494   0.204350  189.162315  ...     0.206718   \n",
       "Topic1   0.204815   0.200698   0.204487    0.205118  ...  1002.288713   \n",
       "Topic2   0.202414  26.917049  60.517739    0.205853  ...  1256.111777   \n",
       "Topic3   0.202276   0.200807   0.205753    0.206344  ...     0.206351   \n",
       "Topic4   0.202470   0.200302   0.203170   47.579606  ...     0.209091   \n",
       "\n",
       "           yearly      yell   yesterday         yet       young      youth  \\\n",
       "Topic0   0.204780  0.200825    0.204247    3.288409    0.204266   0.218053   \n",
       "Topic1   0.204749  8.360062  450.718910    7.669560    0.204423   0.204720   \n",
       "Topic2   0.202394  0.201445    0.205282    0.205315    0.202101  20.095576   \n",
       "Topic3   0.203045  0.201754    0.206369  127.787660    0.203026   0.208391   \n",
       "Topic4  11.707221  0.202593    0.205504  154.308501  143.291485   0.207629   \n",
       "\n",
       "          youtube        yrs       zone  \n",
       "Topic0   0.202620   0.204609   0.202741  \n",
       "Topic1  13.986065   0.203087   0.202043  \n",
       "Topic2   0.207948   0.203849   0.202028  \n",
       "Topic3   0.202225   0.201677   0.201470  \n",
       "Topic4   0.201928  15.891660  57.513947  \n",
       "\n",
       "[5 rows x 3723 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Topic-Keyword Matrix\n",
    "df_topic_keywords = pd.DataFrame(lda_model.components_)# Assign Column and Index\n",
    "df_topic_keywords.columns = vectorizer.get_feature_names_out()\n",
    "df_topic_keywords.index = topicnames# View\n",
    "df_topic_keywords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 0</th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Word 3</th>\n",
       "      <th>Word 4</th>\n",
       "      <th>Word 5</th>\n",
       "      <th>Word 6</th>\n",
       "      <th>Word 7</th>\n",
       "      <th>Word 8</th>\n",
       "      <th>Word 9</th>\n",
       "      <th>Word 10</th>\n",
       "      <th>Word 11</th>\n",
       "      <th>Word 12</th>\n",
       "      <th>Word 13</th>\n",
       "      <th>Word 14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic 0</th>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>job</td>\n",
       "      <td>president</td>\n",
       "      <td>trump</td>\n",
       "      <td>border</td>\n",
       "      <td>think</td>\n",
       "      <td>love</td>\n",
       "      <td>run</td>\n",
       "      <td>work</td>\n",
       "      <td>strong</td>\n",
       "      <td>country</td>\n",
       "      <td>long</td>\n",
       "      <td>hard</td>\n",
       "      <td>people</td>\n",
       "      <td>military</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 1</th>\n",
       "      <td>great</td>\n",
       "      <td>make</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>want</td>\n",
       "      <td>come</td>\n",
       "      <td>people</td>\n",
       "      <td>day</td>\n",
       "      <td>year</td>\n",
       "      <td>see</td>\n",
       "      <td>get</td>\n",
       "      <td>look</td>\n",
       "      <td>true</td>\n",
       "      <td>state</td>\n",
       "      <td>start</td>\n",
       "      <td>leave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 2</th>\n",
       "      <td>trump</td>\n",
       "      <td>get</td>\n",
       "      <td>vote</td>\n",
       "      <td>today</td>\n",
       "      <td>need</td>\n",
       "      <td>new</td>\n",
       "      <td>bad</td>\n",
       "      <td>say</td>\n",
       "      <td>year</td>\n",
       "      <td>election</td>\n",
       "      <td>call</td>\n",
       "      <td>country</td>\n",
       "      <td>good</td>\n",
       "      <td>time</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 3</th>\n",
       "      <td>thank</td>\n",
       "      <td>great</td>\n",
       "      <td>never</td>\n",
       "      <td>many</td>\n",
       "      <td>good</td>\n",
       "      <td>news</td>\n",
       "      <td>know</td>\n",
       "      <td>amp</td>\n",
       "      <td>fake</td>\n",
       "      <td>even</td>\n",
       "      <td>show</td>\n",
       "      <td>medium</td>\n",
       "      <td>much</td>\n",
       "      <td>tonight</td>\n",
       "      <td>interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 4</th>\n",
       "      <td>well</td>\n",
       "      <td>take</td>\n",
       "      <td>deal</td>\n",
       "      <td>world</td>\n",
       "      <td>high</td>\n",
       "      <td>talk</td>\n",
       "      <td>record</td>\n",
       "      <td>big</td>\n",
       "      <td>lose</td>\n",
       "      <td>economy</td>\n",
       "      <td>keep</td>\n",
       "      <td>trade</td>\n",
       "      <td>way</td>\n",
       "      <td>time</td>\n",
       "      <td>soon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Word 0 Word 1           Word 2 Word 3  Word 4  Word 5  \\\n",
       "Topic 0  realdonaldtrump    job        president  trump  border   think   \n",
       "Topic 1            great   make  realdonaldtrump   want    come  people   \n",
       "Topic 2            trump    get             vote  today    need     new   \n",
       "Topic 3            thank  great            never   many    good    news   \n",
       "Topic 4             well   take             deal  world    high    talk   \n",
       "\n",
       "         Word 6 Word 7 Word 8    Word 9  Word 10  Word 11 Word 12  Word 13  \\\n",
       "Topic 0    love    run   work    strong  country     long    hard   people   \n",
       "Topic 1     day   year    see       get     look     true   state    start   \n",
       "Topic 2     bad    say   year  election     call  country    good     time   \n",
       "Topic 3    know    amp   fake      even     show   medium    much  tonight   \n",
       "Topic 4  record    big   lose   economy     keep    trade     way     time   \n",
       "\n",
       "           Word 14  \n",
       "Topic 0   military  \n",
       "Topic 1      leave  \n",
       "Topic 2        win  \n",
       "Topic 3  interview  \n",
       "Topic 4       soon  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show top n keywords for each topic\n",
    "def show_topics(vectorizer=vectorizer, lda_model=lda_model, n_words=20):\n",
    "    keywords = np.array(vectorizer.get_feature_names_out())\n",
    "    topic_keywords = []\n",
    "    for topic_weights in lda_model.components_:\n",
    "        top_keyword_locs = (-topic_weights).argsort()[:n_words]\n",
    "        topic_keywords.append(keywords.take(top_keyword_locs))\n",
    "    return topic_keywords\n",
    "\n",
    "topic_keywords = show_topics(vectorizer=vectorizer, lda_model=lda_model, n_words=15)# Topic - Keywords Dataframe\n",
    "df_topic_keywords = pd.DataFrame(topic_keywords)\n",
    "df_topic_keywords.columns = ['Word '+str(i) for i in range(df_topic_keywords.shape[1])]\n",
    "df_topic_keywords.index = ['Topic '+str(i) for i in range(df_topic_keywords.shape[0])]\n",
    "df_topic_keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os tópicos parecem ser:\n",
    "Topic 0: Nacionalismo americano\n",
    "Topic 2: Campanha e slogan\n",
    "Topic 3: Eleições e críticas aos oponentes\n",
    "Topic 4: Notícias e entrevistas\n",
    "Topic 5: Economia\n",
    "\n",
    "O resultado poderia ser melhor se tivessemos uma lista de palavras stop que abranja erros de digitação e palavras que não são relevantes para a análise. Além disso, a remoção de palavras comuns como \"great\" e \"thank\" poderia melhorar a qualidade dos tópicos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 2\n",
    "\n",
    "Use o dataset \"tweets_trump.csv\" e responda:\n",
    "\n",
    "a) Qual o sentimento dos 5 tweets com maior número de retweets?\n",
    "\n",
    "b) Faça uma análise do sentimento geral de todos os tweets. Para isso, visualize a distribuição de polaridade para embasar a sua resposta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11759    Tonight, @FLOTUS and I tested positive for COV...\n",
       "35620           #FraudNewsCNN #FNN https://t.co/WYUnHjjUjg\n",
       "39347                   TODAY WE MAKE AMERICA GREAT AGAIN!\n",
       "29598    Are you allowed to impeach a president for gro...\n",
       "9080          RT @SpaceX: Liftoff! https://t.co/DRBfdUM7JA\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline #hugging face pipeline\n",
    "import os\n",
    "\n",
    "df = pd.read_csv('kaggle/input/trump_tweets/tweets_trump.csv')\n",
    "\n",
    "df_sorted = df.sort_values('retweets', ascending=False)\n",
    "df_sorted['text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sem realizar processamento podemos ver que o sentimento dos mais retwitados é majoritariamente positivo.\n",
    "Sem contexto  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
